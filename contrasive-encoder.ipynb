{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\nraw_dataset = load_dataset(\"persiannlp/parsinlu_translation_en_fa\")\n\nraw_dataset","metadata":{"execution":{"iopub.status.busy":"2024-02-17T11:22:24.941972Z","iopub.execute_input":"2024-02-17T11:22:24.942768Z","iopub.status.idle":"2024-02-17T11:24:20.905828Z","shell.execute_reply.started":"2024-02-17T11:22:24.942717Z","shell.execute_reply":"2024-02-17T11:24:20.904942Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5e68cbfbee546818a0fedbbda168b84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/2.33k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34b619dab0a54846a290483c70f70a05"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset parsinlu_reading_comprehension/parsinlu-repo (download: 269.39 MiB, generated: 290.18 MiB, post-processed: Unknown size, total: 559.56 MiB) to /root/.cache/huggingface/datasets/persiannlp___parsinlu_reading_comprehension/parsinlu-repo/1.0.0/843d9775153fb139775aa5b2e51839840d6d65fd85ab4218b5e30933dcdef670...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f37ab773710409db16eba6be1ce9435"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/253M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7121e7901e4941b5897fc9699f37cf0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/435k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddc09131e8de43a998df075f4efff649"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/29.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"130ce7b336d845a3a119b58c5dd41978"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"805d3a5e27ea4f7b8ee67ba9e9f2a6ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1621665 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"/root/.cache/huggingface/datasets/downloads/55c737abe7176f5400ad633e32bac2b7e4937e92cebfe8d5e532db9649dd6f04\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/48359 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"/root/.cache/huggingface/datasets/downloads/9844c851544d13187c3f4101de8cc9e13f48c842d93252a10515bf07fb943575\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2137 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"/root/.cache/huggingface/datasets/downloads/4db460fb756175358599a5f7ad7131c3e5fe381b98a8918c0281bc4c6286fc8a\nDataset parsinlu_reading_comprehension downloaded and prepared to /root/.cache/huggingface/datasets/persiannlp___parsinlu_reading_comprehension/parsinlu-repo/1.0.0/843d9775153fb139775aa5b2e51839840d6d65fd85ab4218b5e30933dcdef670. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9808ca9d617d431f9b38fe51b6082648"}},"metadata":{}},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['source', 'targets', 'category'],\n        num_rows: 1621665\n    })\n    test: Dataset({\n        features: ['source', 'targets', 'category'],\n        num_rows: 48359\n    })\n    validation: Dataset({\n        features: ['source', 'targets', 'category'],\n        num_rows: 2137\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"raw_train_dataset = raw_dataset[\"train\"]\nraw_train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-02-17T11:24:29.084133Z","iopub.execute_input":"2024-02-17T11:24:29.084487Z","iopub.status.idle":"2024-02-17T11:24:29.092060Z","shell.execute_reply.started":"2024-02-17T11:24:29.084460Z","shell.execute_reply":"2024-02-17T11:24:29.091178Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'source': 'Due Thank You note by Egyptian blogger Abdel Monem Mahmoud: Following his release from prison, he wrote his first blog titled “Ana ikhwan… I am free”.',\n 'targets': ['بلاگر مصری عبدل منعم محمود (عربی) پس از آزاد شدنش از زندان تیتر اولین مطلب خود را «من آزاد هستم» (عربی) انتخاب کرد.'],\n 'category': 'global_voices_en_fa'}"},"metadata":{}}]},{"cell_type":"code","source":"!pip install open_clip_torch","metadata":{"execution":{"iopub.status.busy":"2024-02-17T11:57:13.707816Z","iopub.execute_input":"2024-02-17T11:57:13.708761Z","iopub.status.idle":"2024-02-17T11:57:27.712690Z","shell.execute_reply.started":"2024-02-17T11:57:13.708720Z","shell.execute_reply":"2024-02-17T11:57:27.711672Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting open_clip_torch\n  Downloading open_clip_torch-2.24.0-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.16.2)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (2023.12.25)\nCollecting ftfy (from open_clip_torch)\n  Downloading ftfy-6.1.3-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (4.66.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.20.3)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.1.99)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (3.20.3)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.9.12)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (2023.12.2)\nRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->open_clip_torch) (0.2.13)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (6.0.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (21.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm->open_clip_torch) (0.4.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->open_clip_torch) (1.24.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->open_clip_torch) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->open_clip_torch) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->open_clip_torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->open_clip_torch) (1.3.0)\nDownloading open_clip_torch-2.24.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: ftfy, open_clip_torch\nSuccessfully installed ftfy-6.1.3 open_clip_torch-2.24.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from open_clip import model\nimport torch\nimport open_clip\n\ndef TextEncoder():\n    return model.TextTransformer(context_length=77, vocab_size=49408, width=512, layers=12, heads=8,\n                                     output_dim=512)","metadata":{"execution":{"iopub.status.busy":"2024-02-17T12:25:05.634504Z","iopub.execute_input":"2024-02-17T12:25:05.635329Z","iopub.status.idle":"2024-02-17T12:25:05.640882Z","shell.execute_reply.started":"2024-02-17T12:25:05.635292Z","shell.execute_reply":"2024-02-17T12:25:05.639820Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"text_encoder_model = TextEncoder()\ntokenizer = open_clip.get_tokenizer('ViT-B-16')","metadata":{"execution":{"iopub.status.busy":"2024-02-17T12:25:06.113465Z","iopub.execute_input":"2024-02-17T12:25:06.114229Z","iopub.status.idle":"2024-02-17T12:25:07.272950Z","shell.execute_reply.started":"2024-02-17T12:25:06.114194Z","shell.execute_reply":"2024-02-17T12:25:07.272136Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"tokens = tokenizer([\"hello baby\"])\ntext_encoder_model(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-02-17T12:25:07.274414Z","iopub.execute_input":"2024-02-17T12:25:07.274712Z","iopub.status.idle":"2024-02-17T12:25:07.279843Z","shell.execute_reply.started":"2024-02-17T12:25:07.274676Z","shell.execute_reply":"2024-02-17T12:25:07.278922Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"checkpoint = \"HooshvareLab/bert-base-parsbert-uncased\"\nfrom transformers import AutoConfig, AutoTokenizer, AutoModel\n\nconfig = AutoConfig.from_pretrained(checkpoint)\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModel.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-02-17T12:36:37.046596Z","iopub.execute_input":"2024-02-17T12:36:37.047402Z","iopub.status.idle":"2024-02-17T12:36:42.838858Z","shell.execute_reply.started":"2024-02-17T12:36:37.047367Z","shell.execute_reply":"2024-02-17T12:36:42.837819Z"},"trusted":true},"execution_count":77,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/434 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9732e043081a46c987561d5b19174d9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/1.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74970575cb2945dbab7d2e3d289cea10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/654M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2742339efe94454ca67e07c9119bdbcd"}},"metadata":{}}]},{"cell_type":"code","source":"text = \"ما در هوشواره معتقدیم با انتقال صحیح دانش و آگاهی، همه افراد می‌توانند از ابزارهای هوشمند استفاده کنند. شعار ما هوش مصنوعی برای همه است.\"\ntokenizer.tokenize(text)","metadata":{"execution":{"iopub.status.busy":"2024-02-17T12:36:42.840686Z","iopub.execute_input":"2024-02-17T12:36:42.841012Z","iopub.status.idle":"2024-02-17T12:36:42.848245Z","shell.execute_reply.started":"2024-02-17T12:36:42.840987Z","shell.execute_reply":"2024-02-17T12:36:42.847360Z"},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"['ما',\n 'در',\n 'هوش',\n '##واره',\n 'معتقدیم',\n 'با',\n 'انتقال',\n 'صحیح',\n 'دانش',\n 'و',\n 'اگاهی',\n '،',\n 'همه',\n 'افراد',\n 'میتوانند',\n 'از',\n 'ابزارهای',\n 'هوشمند',\n 'استفاده',\n 'کنند',\n '.',\n 'شعار',\n 'ما',\n 'هوش',\n 'مصنوعی',\n 'برای',\n 'همه',\n 'است',\n '.']"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}